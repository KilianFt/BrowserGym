{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple MCTS\n",
    "This notebook investigates using MCTS for a single static website where multiple actions have to be done to achieve an answer.\n",
    "\n",
    "The task is to order a macbook with certain configurations. This website was chosen over others because it does not change upon selecting certain elements, which substantially simplifies testing as a website can simply be cached.\n",
    "\n",
    "The start domain is [this page](https://www.apple.com/shop/buy-mac/macbook-pro/14-inch-space-gray-apple-m3-chip-with-8-core-cpu-and-10-core-gpu-8gb-memory-512gb) with the prompt \"order a macbook pro 14 with 24 gb, 2 tb, fast charging and all available software\"\n",
    "\n",
    "Command to run this:\n",
    "```\n",
    "python run_demo.py --task_name openended --model_name openai/gpt-4o-mini --start_url https://www.apple.com/shop/buy-mac/macbook-pro/14-inch-space-gray-apple-m3-chip-with-8-core-cpu-and-10-core-gpu-8gb-memory-512gb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and load cached website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = \"https://www.apple.com/shop/buy-mac/macbook-pro/14-inch-space-gray-apple-m3-chip-with-8-core-cpu-and-10-core-gpu-8gb-memory-512gb\"\n",
    "\n",
    "human_prompt = \"order a macbook pro 14 with 24 gb ram, 2 tb, fast charging and all available software\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideal actions are:\n",
    "ideal_actions = [\n",
    "    \"click(1007)\",  # Select 24GB unified memory\n",
    "    \"click(1038)\",  # Select 2TB SSD storage\n",
    "    \"click(1061)\",  # Select 96W USB-C Power Adapter\n",
    "    \"click(1112)\",  # Select Final Cut Pro software\n",
    "    \"click(1135)\",  # Select Logic Pro software\n",
    "    \"click(1209)\",  # Add to bag\n",
    "]\n",
    "updated_ideal_actions = [\n",
    "    'click(1008)',\n",
    "    'click(1039)',\n",
    "    'click(1062)',\n",
    "    'click(1113)',\n",
    "    'click(1136)',\n",
    "    'click(1209)']\n",
    "\n",
    "# ideal_actions_str = \"\\n\".join(ideal_actions)\n",
    "\n",
    "ideal_actions = updated_ideal_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = \"../output_example_2.txt\"\n",
    "with open(txt_file, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "system_messages = []\n",
    "prompts = []\n",
    "actions = []\n",
    "\n",
    "current_section = None\n",
    "\n",
    "for line in lines:\n",
    "    if line.startswith(\"System Message:\"):\n",
    "        current_section = \"System Message\"\n",
    "    elif line.startswith(\"Prompt:\"):\n",
    "        current_section = \"Prompt\"\n",
    "    elif line.startswith(\"Action:\"):\n",
    "        current_section = \"Action\"\n",
    "    else:\n",
    "        if current_section == \"System Message\":\n",
    "            system_messages.append(line)\n",
    "        elif current_section == \"Prompt\":\n",
    "            prompts.append(line)\n",
    "        elif current_section == \"Action\":\n",
    "            actions.append(line)\n",
    "\n",
    "system_prompt = system_messages[0].split(\"content='\")[-1].strip()\n",
    "base_prompt = prompts[0].split(\"content=\\'\")[-1].strip()\n",
    "# ideal_actions = actions[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/agents/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../demo_agent\")\n",
    "from agents.legacy.dynamic_prompting import Think, Memory, ActionSpace, Flags\n",
    "\n",
    "flags=Flags(\n",
    "    use_html=True,\n",
    "    use_ax_tree=True,\n",
    "    use_thinking=True,  # \"Enable the agent with a memory (scratchpad).\"\n",
    "    use_error_logs=True,  # \"Prompt the agent with the error logs.\"\n",
    "    use_memory=False,  # \"Enables the agent with a memory (scratchpad).\"\n",
    "    use_history=True,\n",
    "    use_diff=False,  # \"Prompt the agent with the difference between the current and past observation.\"\n",
    "    use_past_error_logs=True,  # \"Prompt the agent with the past error logs.\"\n",
    "    use_action_history=True,  # \"Prompt the agent with the action history.\"\n",
    "    multi_actions=True,\n",
    "    action_space=\"bid\",\n",
    "    use_abstract_example=True,  # \"Prompt the agent with an abstract example.\"\n",
    "    use_concrete_example=True,  # \"Prompt the agent with a concrete example.\"\n",
    "    use_screenshot=False,\n",
    "    enable_chat=True,\n",
    "    demo_mode=\"default\",\n",
    ")\n",
    "\n",
    "think = Think(visible=lambda: flags.use_thinking)\n",
    "memory = Memory(visible=lambda: flags.use_memory)\n",
    "action_space = ActionSpace(flags)\n",
    "\n",
    "def parser(text_answer):\n",
    "    ans_dict = {}\n",
    "    try:\n",
    "        ans_dict.update(think._parse_answer(text_answer))\n",
    "        ans_dict.update(memory._parse_answer(text_answer))\n",
    "        ans_dict.update(action_space._parse_answer(text_answer))\n",
    "    except Exception as e:\n",
    "        ans_dict['action'] = None\n",
    "        ans_dict['think'] = None\n",
    "\n",
    "    return ans_dict, True, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "with open(\"../openai_key.txt\", \"r\") as file:\n",
    "    api_key = file.read().strip()\n",
    "\n",
    "model = ChatOpenAI(\n",
    "            model_name=\"gpt-4o-mini\",\n",
    "            temperature=0.1,\n",
    "            max_tokens=2_000,\n",
    "            api_key=api_key\n",
    "        ).bind(logprobs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries: clean html and build prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class HTMLCleaner(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.output = []\n",
    "        self.tag_stack = []\n",
    "        self.current_content = []\n",
    "        self.interactive_elements = {\n",
    "            'a', 'button', 'input', 'select', 'textarea', 'label', 'fieldset',\n",
    "            'legend', 'datalist', 'output', 'option', 'optgroup'\n",
    "        }\n",
    "\n",
    "    def is_interactive(self, tag, attrs):\n",
    "        if tag.lower() in self.interactive_elements:\n",
    "            return True\n",
    "        return any(attr[0] == 'onclick' for attr in attrs)\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag.lower() == 'img':\n",
    "            return\n",
    "        \n",
    "        is_interactive = self.is_interactive(tag, attrs)\n",
    "        bid_attr = next((attr for attr in attrs if attr[0] == 'bid'), None)\n",
    "        \n",
    "        if bid_attr and not is_interactive:\n",
    "            bid_attr = None\n",
    "\n",
    "        self.tag_stack.append((tag, bid_attr, len(self.output)))\n",
    "        self.current_content.append([])\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        if tag.lower() == 'img':\n",
    "            return\n",
    "\n",
    "        if self.tag_stack and self.tag_stack[-1][0] == tag:\n",
    "            start_tag, bid_attr, start_index = self.tag_stack.pop()\n",
    "            content = ''.join(self.current_content.pop()).strip()\n",
    "\n",
    "            if content:\n",
    "                if bid_attr:\n",
    "                    self.output.insert(start_index, f'<{start_tag} bid=\"{bid_attr[1]}\">')\n",
    "                else:\n",
    "                    self.output.insert(start_index, f'<{start_tag}>')\n",
    "                self.output.append(content)\n",
    "                self.output.append(f'</{tag}>')\n",
    "\n",
    "            if self.current_content:\n",
    "                self.current_content[-1].extend(self.output[start_index:])\n",
    "                del self.output[start_index:]\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        normalized_data = re.sub(r'(\\\\n|\\n|\\r)+', '', data)\n",
    "        normalized_data = re.sub(r'\\s+', ' ', normalized_data)\n",
    "        if self.current_content:\n",
    "            self.current_content[-1].append(normalized_data)\n",
    "        else:\n",
    "            self.output.append(normalized_data)\n",
    "\n",
    "def clean_html(html_content):\n",
    "    html_content = html_content.replace('\\\\n', '\\n')\n",
    "    cleaner = HTMLCleaner()\n",
    "    cleaner.feed(html_content)\n",
    "    return ''.join(cleaner.output).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288727, 32333)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = base_prompt.split(\"# \")[4]\n",
    "c_html = clean_html(html)\n",
    "len(html), len(c_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_action_space = \"\"\"Action space:\\\\n\\\\1 type of actions are available.\\\\n\\\\nclick(bid: int)\\\\n    Description: Click an element.\\\\n    Examples:\\\\n        click(\\\\\\'151\\\\\\')\\\\n\\\\n    Multiple actions can be provided at once, but will be executed sequentially without any feedback from the page.\\\\nExample:\\\\nfill(\\\\\\'a12\\\\\\', \\\\\\'example with \"quotes\"\\\\\\')\\\\nclick(\\\\\\'a51\\\\\\')\\\\nclick(\\\\\\'48\\\\\\', button=\\\\\\'middle\\\\\\', modifiers=[\\\\\\'Shift\\\\\\'])\\\\n\\\\n\"\"\"\n",
    "\n",
    "def build_action_prompt(base_prompt, actions, action_thoughts, thoughts):\n",
    "    base_splits = base_prompt.split(\"# \")\n",
    "    # change html obs\n",
    "    html = base_splits[4][7:]\n",
    "    base_splits[4] = \"HTML:\" + clean_html(html)\n",
    "\n",
    "    hist_split = base_splits[6]\n",
    "    hist_instruction = hist_split[:-4]\n",
    "    hist_end = hist_split[-4:]\n",
    "    act_thought_list = [a + \" #\" + t for a, t in zip(actions, action_thoughts)]\n",
    "    new_hist = hist_instruction + \" Actions: [\" + \", \".join(act_thought_list) + \"]; Thoughts [\" + \", \".join(thoughts) + \"]\" + hist_end\n",
    "    base_splits[6] = new_hist\n",
    "    base_splits[7] = simple_action_space\n",
    "    new_prompt = \"# \".join(base_splits)\n",
    "    new_prompt += \" # Final Instruction: Given that the last actions are: \" + \", \".join(actions) + \", what would you do next? Do not pick an action that you already tried.\"\n",
    "    return new_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth\n",
    "actions = []\n",
    "action_thoughts = []\n",
    "thoughts = []\n",
    "\n",
    "new_prompt = build_action_prompt(base_prompt, actions, action_thoughts, thoughts)\n",
    "chat_messages = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(content=new_prompt+\"Think about what to do and then predict all actions at once to complete the task.\"),\n",
    "]\n",
    "out = model.invoke(chat_messages)\n",
    "ans_dict = parser(out.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:\n",
      "fill('memory_aos_phantom_z1c8_065_cg1l_3', '')  # Select 24GB RAM\n",
      "fill('hard_drivesolid_state_drive_aos_phantom_z1c8_065_cg1p_3', '')  # Select 2TB SSD Storage\n",
      "click('sw_final_cut_pro_z1c8_065_cg37_2')  # Select Final Cut Pro\n",
      "click('sw_logic_pro_z1c8_065_cg39_2')  # Select Logic Pro\n",
      "click('1208')  # Click add to cart button\n",
      "\n",
      "Ideal:\n",
      "click('1007') # Select 24GB unified memory\n",
      "click('1038') # Select 2TB SSD storage\n",
      "click('1061') # Select 96W USB-C Power Adapter\n",
      "click('1112') # Select Final Cut Pro software\n",
      "click('1135') # Select Logic Pro software\n",
      "click('1209') # Add to bag\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted:\\n{ans_dict[0]['action']}\")\n",
    "print(f\"\\nIdeal:\\n{ideal_actions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Action(BaseModel):\n",
    "    think: str = Field(description=\"The goal of the next step to eventually accomplish the task\")\n",
    "    action: str = Field(description=\"The single action to accomplish the task. Should be click(<int>)\")\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    think: str = Field(description=\"The overall goal and thoughts to accomplish the task\")\n",
    "    plan: List[Action] = Field(description=\"Possible actions to take next to get closer to the goal. Should have length of at least 7\")\n",
    "\n",
    "structured_llm = model.with_structured_output(Plan, include_raw=True)\n",
    "greedy_llm = model.with_structured_output(Action, include_raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_predict(action_prompt):\n",
    "    chat_messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=action_prompt),\n",
    "    ]\n",
    "    answer = structured_llm.invoke(chat_messages)\n",
    "    return answer\n",
    "\n",
    "def greedy_predict(action_prompt):\n",
    "    chat_messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=action_prompt),\n",
    "    ]\n",
    "    answer = greedy_llm.invoke(chat_messages)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = []\n",
    "action_thoughts = []\n",
    "thoughts = []\n",
    "\n",
    "new_prompt = build_action_prompt(base_prompt, actions, action_thoughts, thoughts)\n",
    "\n",
    "expand_answer = expand_predict(new_prompt)\n",
    "greedy_answer = greedy_predict(new_prompt)\n",
    "\n",
    "print([p.action for p in expand_answer.plan])\n",
    "print(greedy_answer.action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, actions, action_thoughts, thoughts, parent=None, depth=0):\n",
    "        self.actions = actions\n",
    "        self.action_thoughts = action_thoughts\n",
    "        self.thoughts = thoughts\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.visits = 1  # add 1 to avoid division by 0 and thus never have inf value\n",
    "        self.value = 0.01\n",
    "        self.depth = depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tree helper functions\n",
    "\n",
    "def print_tree(node, indent=\"\"):\n",
    "    if len(node.actions) > 0:\n",
    "        # print(f\"{indent}Thoughts: {node.thoughts[-1]}\")\n",
    "        # print(f\"{indent}Action Thoughts: {node.action_thoughts[-1]}\")\n",
    "        print(f\"{indent}Action: {node.actions[-1]}\")\n",
    "        print(f\"{indent}Value: {node.value}\")\n",
    "    print(f\"{indent}Children: {len(node.children)}\")\n",
    "    for child in node.children:\n",
    "        print_tree(child, indent + \"  \")\n",
    "\n",
    "# create all possible trajectories of actions from tree\n",
    "def get_trajectories(node):\n",
    "    if not node.children:\n",
    "        return [[node.actions]]\n",
    "    \n",
    "    trajectories = []\n",
    "    for child in node.children:\n",
    "        child_trajectories = get_trajectories(child)\n",
    "        for trajectory in child_trajectories:\n",
    "            trajectories.append([node.actions] + trajectory)\n",
    "    \n",
    "    trajectories = [t[-1] for t in trajectories]\n",
    "    return trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import math\n",
    "import random\n",
    "\n",
    "def select(node: Node, alpha: float = 1.0) -> Node:\n",
    "    while node.children:\n",
    "        if len(node.children) < 1:\n",
    "            return node\n",
    "        node = ucb_select(node, alpha)\n",
    "    return node\n",
    "\n",
    "def ucb_select(node: Node, alpha: float = 1.0) -> Node:\n",
    "    scores = [ucb_score(c, node.visits, alpha) for c in node.children]\n",
    "    max_score = max(scores)\n",
    "    max_children = [c for c, s in zip(node.children, scores) if s == max_score]\n",
    "    return random.choice(max_children)\n",
    "\n",
    "def ucb_score(node: Node, total_visits: int, alpha: float = 1.0) -> float:\n",
    "    if node.visits == 0:\n",
    "        return float('inf')\n",
    "    return (node.value / node.visits) + alpha * math.sqrt(2 * math.log(total_visits) / node.visits)\n",
    "\n",
    "def expand(node: Node) -> Node:\n",
    "    # this should be taking an action and getting to a new state\n",
    "    answer = expand_predict(build_action_prompt(base_prompt, root.actions, root.action_thoughts, root.thoughts))\n",
    "    parsed_answer = answer['parsed']\n",
    "    new_thought = parsed_answer.think\n",
    "    for action in parsed_answer.plan:\n",
    "        new_actions = node.actions + [action.action]\n",
    "        new_action_thoughts = node.action_thoughts + [action.think]\n",
    "        new_thoughts = node.thoughts + [new_thought]\n",
    "        child = Node(copy.deepcopy(new_actions),\n",
    "                     copy.deepcopy(new_action_thoughts),\n",
    "                     copy.deepcopy(new_thoughts),\n",
    "                     parent=node,\n",
    "                     depth=node.depth+1)\n",
    "        node.children.append(child)\n",
    "\n",
    "def backpropagate(node: Node, reward: float):\n",
    "    while node:\n",
    "        node.visits += 1\n",
    "        node.value += reward\n",
    "        node = node.parent\n",
    "\n",
    "def verify_success(actions):\n",
    "    if actions == ideal_actions:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def best_child(node: Node) -> Node:\n",
    "    max_visits = max(c.visits for c in node.children)\n",
    "    candidates = [c for c in node.children if c.visits == max_visits]\n",
    "    return max(candidates, key=lambda c: c.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.5)"
      ]
     },
     "execution_count": 924,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_t_value(trajectory):\n",
    "    # FIXME this is a hacky way to handle the fact that the bids are not assigned nicely\n",
    "    for i, t in enumerate(trajectory):\n",
    "        if t == 'click(1006)':\n",
    "            trajectory[i] = 'click(1007)'\n",
    "        if t == 'click(1039)':\n",
    "            trajectory[i] = 'click(1038)'\n",
    "\n",
    "    correct_actions = 0.\n",
    "    for a, b in zip(trajectory, ideal_actions):\n",
    "        if a == b:\n",
    "            correct_actions += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    score = correct_actions / len(ideal_actions)\n",
    "\n",
    "    return score\n",
    "\n",
    "t = ['click(1007)', 'click(1039)', 'click(1061)', 'click(1112)\\nclick(1136)']\n",
    "get_t_value(ideal_actions), get_t_value(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['click(1007)', 'click(1038)', 'click(1038)', 'click(1038)', 'click(1061)', 'click(1062)'] 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# greedy baseline\n",
    "max_depth = 6\n",
    "\n",
    "actions = []\n",
    "action_thoughts = []\n",
    "thoughts = []\n",
    "\n",
    "root = Node(actions, action_thoughts, thoughts)\n",
    "\n",
    "for _ in range(max_depth):\n",
    "    out = greedy_predict(build_action_prompt(base_prompt, root.actions, root.action_thoughts, root.thoughts))\n",
    "    answer = out['parsed']\n",
    "    root.action_thoughts += [answer.think]\n",
    "    root.actions += [answer.action]\n",
    "print(root.actions, get_t_value(root.actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# get initial options\n",
    "max_depth = 6\n",
    "max_iters = 200\n",
    "alpha = 0.7\n",
    "\n",
    "actions = []\n",
    "action_thoughts = []\n",
    "thoughts = []\n",
    "\n",
    "root = Node(actions, action_thoughts, thoughts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [43:11<00:00, 12.96s/it]\n"
     ]
    }
   ],
   "source": [
    "for iter_idx in tqdm(range(max_iters)):\n",
    "    # selection\n",
    "    # - TODO figure out how to do this proportional to logprobs\n",
    "    selected_node = select(root, alpha)\n",
    "\n",
    "    # expansion + simulation\n",
    "    remaining_depth = max_depth - selected_node.depth\n",
    "\n",
    "    value = get_t_value(selected_node.actions)\n",
    "\n",
    "    if remaining_depth > 0:\n",
    "        for _ in range(remaining_depth):\n",
    "            expand(selected_node)\n",
    "            selected_node = select(selected_node)\n",
    "            value = get_t_value(selected_node.actions)\n",
    "            if value == 1.0:\n",
    "                break\n",
    "\n",
    "    # backpropagation\n",
    "    backpropagate(selected_node, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['click(1007)', 'click(1038)', 'click(1061)', 'click(1112)', 'click(1209)', 'click(1204)', 'click(1204)']\n",
      "[15.509999999999993, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
      "[72, 23, 22, 23, 22, 23, 22]\n",
      "['click(1007)', 'click(1038)', 'click(1209)', 'click(1100)', 'click(1118)', 'click(1141)', 'click(1204)']\n",
      "[1.5100000000000002, 6.676666666666665, 1.5100000000000002, 1.5100000000000002, 1.5100000000000002, 1.3433333333333335, 1.5100000000000002]\n",
      "[10, 19, 10, 10, 10, 9, 10]\n",
      "['click(1007)', 'click(1038)', 'click(1061)', 'click(1100)', 'click(1112)', 'click(1135)', 'click(1209)']\n",
      "[0.6766666666666666, 0.6766666666666666, 2.01, 0.6766666666666666, 0.6766666666666666, 1.01, 1.01]\n",
      "[3, 3, 5, 3, 3, 4, 4]\n",
      "['click(1007)', 'click(1038)', 'click(1061)', 'click(1112)', 'click(1209)', 'click(1204)', 'click(1204)']\n",
      "[0.51, 1.01, 0.51, 0.01, 0.01, 0.01, 0.01]\n",
      "[2, 3, 2, 1, 1, 1, 1]\n",
      "['click(1006)', 'click(1039)', 'click(1061)', 'click(1072)', 'click(1112)', 'click(1135)', 'click(1209)']\n",
      "[0.01, 0.01, 0.01, 0.01, 0.01, 1.01, 0.01]\n",
      "[1, 1, 1, 1, 1, 3, 1]\n",
      "['click(1006)', 'click(1038)', 'click(1061)', 'click(1112)', 'click(1209)', 'click(1204)', 'click(1208)']\n",
      "[0.01, 1.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
      "[1, 3, 1, 1, 1, 1, 1]\n",
      "\n",
      "Best trajectory:['click(1007)', 'click(1038)', 'click(1061)', 'click(1038)', 'click(1135)', 'click(1038)']\n",
      "Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "best_c = copy.deepcopy(root)\n",
    "while best_c.children:\n",
    "    print([c.actions[-1] for c in best_c.children])\n",
    "    print([c.value for c in best_c.children])\n",
    "    print([c.visits for c in best_c.children])\n",
    "    best_c = best_child(best_c)\n",
    "print(f\"\\nBest trajectory:{best_c.actions}\\nScore: {get_t_value(best_c.actions)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
